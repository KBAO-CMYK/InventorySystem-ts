import os
import shutil
import hashlib
from utils import *  # å¯¼å…¥ä½ çš„utilsæ‰€æœ‰å‡½æ•°/é…ç½®
import logging

# é€‚é…é¡¹ç›®æ—¥å¿—
logger = logging.getLogger(__name__)


def undo_last_change(confirm=False, table_name=None):
    """
    å¢å¼ºç‰ˆæ’¤é”€å‡½æ•°ï¼šé»˜è®¤æ¢å¤æ‰€æœ‰æœ‰å¤‡ä»½çš„è¡¨ï¼ˆå›é€€ä¸Šä¸€æ“ä½œä¿®æ”¹çš„æ‰€æœ‰è¡¨ï¼‰
    :param confirm: æ˜¯å¦ç¡®è®¤ï¼ˆAPIè°ƒç”¨å›ºå®šä¸ºFalseï¼‰
    :param table_name: è¦æ¢å¤çš„è¡¨åï¼ˆNone=æ¢å¤æ‰€æœ‰æœ‰å¤‡ä»½çš„è¡¨ï¼ŒæŒ‡å®šåˆ™ä»…æ¢å¤è¯¥è¡¨ï¼‰
    :return: dict - åŒ…å«successã€messageã€restoredã€debug_info
    """
    debug_info = {}
    try:
        # ========== å…³é”®1ï¼šå¼ºåˆ¶è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆè§£å†³ç›¸å¯¹è·¯å¾„æ··ä¹±ï¼‰ ==========
        abs_csv_dir = os.path.abspath(CSV_DIR)
        debug_info["csv_dir_abs"] = abs_csv_dir
        ensure_csv_directory()  # ç¡®ä¿CSVç›®å½•å­˜åœ¨

        backup_exists = False
        # æ ¸å¿ƒä¿®æ”¹ï¼šé»˜è®¤éå†æ‰€æœ‰è¡¨ï¼ˆtable_name=Noneæ—¶ï¼‰ï¼Œè€Œéä»…å•ä¸ªè¡¨
        target_tables = CSV_FILES.keys() if table_name is None else [table_name]
        debug_info["target_tables"] = list(target_tables)

        # æ ¡éªŒè¡¨æ˜¯å¦å­˜åœ¨ + æ£€æŸ¥æ‰€æœ‰ç›®æ ‡è¡¨çš„å¤‡ä»½æ–‡ä»¶
        table_backup_map = {}  # è®°å½•æ¯ä¸ªè¡¨çš„å¤‡ä»½æ–‡ä»¶è·¯å¾„å’ŒMD5
        for table in target_tables:
            if table not in CSV_FILES:
                error_msg = f"è¡¨ {table} ä¸å­˜åœ¨äºé…ç½®çš„CSV_FILESä¸­"
                logger.error(f"âŒ {error_msg}")
                return {
                    "success": False,
                    "message": error_msg,
                    "restored": [],
                    "debug_info": debug_info
                }

            # ç»å¯¹è·¯å¾„è®¡ç®—
            filepath = os.path.abspath(CSV_FILES[table])
            backup_file = f"{filepath}.backup"
            table_backup_map[table] = {
                "csv_abs": filepath,
                "backup_abs": backup_file,
                "csv_exists": os.path.exists(filepath),
                "backup_exists": os.path.exists(backup_file)
            }

            # è®¡ç®—MD5ï¼ˆéªŒè¯å†…å®¹ï¼‰
            def get_md5(f):
                if not os.path.exists(f):
                    return "ä¸å­˜åœ¨"
                md5 = hashlib.md5()
                with open(f, 'rb') as f_obj:
                    while chunk := f_obj.read(4096):
                        md5.update(chunk)
                return md5.hexdigest()

            table_backup_map[table]["csv_md5_before"] = get_md5(filepath)
            table_backup_map[table]["backup_md5"] = get_md5(backup_file)

            if os.path.exists(backup_file):
                backup_exists = True

        debug_info["table_backup_map"] = table_backup_map

        if not backup_exists:
            error_msg = "æ— å¯ç”¨çš„å¤‡ä»½æ–‡ä»¶ï¼Œæ— æ³•æ‰§è¡Œæ’¤é”€æ“ä½œ"
            logger.error(f"âŒ {error_msg}")
            return {
                "success": False,
                "message": error_msg,
                "restored": [],
                "debug_info": debug_info
            }

        # ========== å…³é”®2ï¼šéå†æ‰€æœ‰ç›®æ ‡è¡¨ï¼Œæ¢å¤æ‰€æœ‰æœ‰å¤‡ä»½çš„è¡¨ ==========
        restored = []
        for table in target_tables:
            tb_info = table_backup_map[table]
            filepath = tb_info["csv_abs"]
            backup_file = tb_info["backup_abs"]

            if tb_info["backup_exists"]:
                # 1. å…ˆåˆ é™¤åŸæ–‡ä»¶ï¼ˆç¡®ä¿è¦†ç›–ï¼Œé¿å…æ–‡ä»¶å ç”¨ï¼‰
                if tb_info["csv_exists"]:
                    os.remove(filepath)
                    logger.info(f"åˆ é™¤åŸCSVæ–‡ä»¶ï¼š{filepath}")

                # 2. å¤åˆ¶å¤‡ä»½æ–‡ä»¶ï¼ˆå¼ºåˆ¶è¦†ç›–ï¼‰
                shutil.copy2(backup_file, filepath)
                # 3. å¼ºåˆ¶åˆ·æ–°æ–‡ä»¶ç³»ç»Ÿï¼ˆè§£å†³å»¶è¿Ÿç”Ÿæ•ˆï¼‰
                os.sync()

                # 4. éªŒè¯æ¢å¤ç»“æœ
                tb_info["csv_md5_after"] = get_md5(filepath)
                if tb_info["csv_md5_after"] == tb_info["backup_md5"]:
                    restored.append(table)
                    logger.info(f"âœ… è¡¨ {table} å·²ä»å¤‡ä»½æ¢å¤ï¼ˆMD5ä¸€è‡´ï¼‰")
                else:
                    logger.error(f"âŒ è¡¨ {table} æ¢å¤åMD5ä¸ä¸€è‡´")

        # ========== å…³é”®3ï¼šå½»åº•æ¸…ç©ºç¼“å­˜ï¼ˆé€‚é…utilsçš„åŒå±‚ç¼“å­˜ï¼‰ ==========
        invalidate_cache()  # æ¸…ç©ºlru_cache
        # æ¸…ç©ºutilsé‡Œçš„å…¨å±€ç¼“å­˜
        global _data_cache, _cache_timestamp
        _data_cache = {}
        _cache_timestamp = None
        logger.info("âœ… æ‰€æœ‰ç¼“å­˜å·²å½»åº•æ¸…ç©º")

        # ========== å…³é”®4ï¼šç¦ç”¨utilsçš„è‡ªåŠ¨ä¿®å¤ï¼ˆä¸´æ—¶ï¼‰ ==========
        # è¯»å–ä¸€æ¬¡æ•°æ®ï¼Œç¡®ä¿ç¼“å­˜åŠ è½½æ–°æ•°æ®ï¼ˆè€Œéè‡ªåŠ¨ä¿®å¤ï¼‰
        read_csv_data()

        success_msg = f"æˆåŠŸæ¢å¤è¡¨ï¼š{', '.join(restored)}ï¼ˆå…±{len(restored)}ä¸ªè¡¨ï¼ŒMD5æ ¡éªŒä¸€è‡´ï¼‰"
        logger.info(f"ğŸ‰ {success_msg}")
        return {
            "success": True,
            "message": success_msg,
            "restored": restored,
            "debug_info": debug_info
        }

    except Exception as e:
        error_msg = f"æ’¤é”€æ“ä½œå¤±è´¥ï¼š{str(e)}"
        logger.error(f"âŒ {error_msg}", exc_info=True)
        return {
            "success": False,
            "message": error_msg,
            "restored": [],
            "debug_info": debug_info
        }