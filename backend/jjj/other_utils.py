# other_utils.py
import pandas as pd
import numpy as np
from datetime import datetime
import os
from config import *
from read_utils import timing_decorator, TimingTracker, CSV_FILES, CSV_DIR, ensure_csv_directory, safe_read_csv_files, invalidate_cache
from write_utils import get_required_columns, get_empty_dataframe_template, get_unique_boxes_by_floor, safe_write_csv_files


# ------------------- æ•°æ®å¤„ç†å·¥å…·å‡½æ•° -------------------
@timing_decorator
def generate_auto_id_df(df, id_column="ID"):
    """ä¸ºDataFrameç”Ÿæˆè‡ªå¢ID"""
    if df.empty or id_column not in df.columns or df[id_column].empty:
        return 1

    valid_ids = []
    for id_val in df[id_column].tolist():
        if isinstance(id_val, (int, float)) and not pd.isna(id_val):
            valid_ids.append(int(id_val))

    return max(valid_ids) + 1 if valid_ids else 1


@timing_decorator
def convert_to_serializable(value):
    """ä¼˜åŒ–çš„åºåˆ—åŒ–è½¬æ¢å‡½æ•°"""
    if pd.isna(value) or value == "" or value is None:
        return ""
    elif isinstance(value, (np.integer, np.int64, np.int32)):
        return int(value)
    elif isinstance(value, (np.floating, np.float64, np.float32)):
        return float(value) if not pd.isna(value) else 0.0
    elif isinstance(value, datetime):
        return value.strftime("%Y-%m-%d %H:%M:%S")
    elif isinstance(value, np.bool_):
        return bool(value)
    else:
        return str(value) if not isinstance(value, (str, int, float, bool)) else value


@timing_decorator
def df_to_serializable_list(df):
    """æ‰¹é‡è½¬æ¢DataFrameä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸åˆ—è¡¨"""
    if df.empty:
        return []
    return df.applymap(convert_to_serializable).to_dict('records')


@timing_decorator
def get_unit_by_addr_type(addr_type):
    if addr_type == 1:
        return "æ¡†"
    elif addr_type in [2, 3]:
        return "åŒ…"
    elif addr_type in [4, 5, 6]:
        return "ä¸ª"
    else:
        return "ä¸ª"


@timing_decorator
def update_stock_capacity(floor, inventory_list, stock_capacity_df):
    """æ›´æ–°æŒ‡å®šæ¥¼å±‚çš„å‰©ä½™å®¹é‡ï¼Œæ— è®°å½•åˆ™åˆ›å»º"""
    used_boxes = len(get_unique_boxes_by_floor(floor, inventory_list))

    floor_capacity_rows = stock_capacity_df[stock_capacity_df["æ¥¼å±‚"] == floor]

    if floor_capacity_rows.empty:
        floor_capacity = {
            "æ¥¼å±‚": floor,
            "æ¥¼å±‚å®¹é‡": FLOOR_CAPACITY,
            "æ¥¼å±‚å‰©ä½™å®¹é‡": max(0, FLOOR_CAPACITY - used_boxes)
        }
        new_row = pd.DataFrame([floor_capacity])
        stock_capacity_df = pd.concat([stock_capacity_df, new_row], ignore_index=True)
        return floor_capacity, stock_capacity_df
    else:
        index = floor_capacity_rows.index[0]
        stock_capacity_df.at[index, "æ¥¼å±‚å‰©ä½™å®¹é‡"] = max(0, FLOOR_CAPACITY - used_boxes)
        return stock_capacity_df.iloc[index].to_dict(), stock_capacity_df


@timing_decorator
def update_inventory_status(inventory_id, csv_data):
    """æ›´æ–°åº“å­˜çŠ¶æ€"""
    inventory_df = csv_data["inventory"]

    mask = inventory_df["ID"] == inventory_id
    if not inventory_df[mask].any().any():
        return

    current_stock = inventory_df.loc[mask, "å…¥åº“æ•°é‡"].iloc[0] - inventory_df.loc[mask, "å‡ºåº“æ€»æ•°é‡"].iloc[0]
    inventory_df.loc[mask, "åº“å­˜æ•°é‡"] = current_stock

    if current_stock > 0:
        status = "å·²å…¥åº“"
    elif current_stock == 0:
        status = "å·²å‡ºåº“"
    else:
        status = "æœªçŸ¥åº“å­˜"

    inventory_df.loc[mask, "çŠ¶æ€"] = status


# ------------------- æ•°æ®åˆå§‹åŒ–å‡½æ•° -------------------
@timing_decorator
def init_or_fix_csv_files():
    """åˆå§‹åŒ–æˆ–ä¿®å¤CSVæ–‡ä»¶ - å®‰å…¨çš„åˆå§‹åŒ–æµç¨‹"""
    # ç¡®ä¿CSVç›®å½•å­˜åœ¨
    ensure_csv_directory()

    # é¦–å…ˆå°è¯•è¯»å–ç°æœ‰æ•°æ®
    data = safe_read_csv_files()

    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæˆ–ä¿®å¤æ–‡ä»¶
    needs_creation = False
    needs_repair = False

    for table in REQUIRED_TABLES:
        filepath = CSV_FILES[table]
        if not os.path.exists(filepath):
            print(f"ğŸ“ {table} æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»º")
            needs_creation = True
        elif table not in data or data[table] is None or data[table].empty:
            print(f"âš ï¸ {table} æ•°æ®ä¸ºç©ºæˆ–æŸåï¼Œéœ€è¦ä¿®å¤")
            needs_repair = True
        else:
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_cols = get_required_columns(table)
            if required_cols:
                existing_cols = set(data[table].columns)
                missing_cols = set(required_cols) - existing_cols
                if missing_cols:
                    print(f"âš ï¸ {table} ç¼ºå°‘åˆ—: {missing_cols}ï¼Œéœ€è¦ä¿®å¤")
                    needs_repair = True

    if needs_creation:
        print("ğŸ†• åˆ›å»ºæ–°çš„CSVæ–‡ä»¶")
        result = create_new_csv_files()
        invalidate_cache()
        return result
    elif needs_repair:
        print("ğŸ”§ ä¿®å¤CSVæ–‡ä»¶ç»“æ„")
        try:
            result = repair_csv_structure(data)
            invalidate_cache()
            return result
        except Exception as e:
            print(f"âŒ ä¿®å¤å¤±è´¥: {str(e)}ï¼Œå°è¯•é‡æ–°åˆ›å»º")
            result = create_new_csv_files()
            invalidate_cache()
            return result
    else:
        print("âœ… CSVæ–‡ä»¶çŠ¶æ€æ­£å¸¸")
        return True


@timing_decorator
def create_new_csv_files():
    """åˆ›å»ºæ–°çš„CSVæ–‡ä»¶ - å®‰å…¨çš„åˆ›å»ºæµç¨‹"""
    try:
        # ç¡®ä¿CSVç›®å½•å­˜åœ¨
        ensure_csv_directory()

        # è¯»å–ç°æœ‰æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        existing_data = safe_read_csv_files()

        # åˆ›å»ºæ ‡å‡†æ•°æ®ç»“æ„
        new_data = {
            'inventory': get_empty_dataframe_template('inventory'),
            'manufacturer': get_empty_dataframe_template('manufacturer'),
            'feature': get_empty_dataframe_template('feature'),
            'stock_capacity': get_empty_dataframe_template('stock_capacity'),
            'stock_out_records': get_empty_dataframe_template('stock_out_records')
        }

        # åˆå¹¶ç°æœ‰æ•°æ®å’Œæ–°æ•°æ®ç»“æ„
        merged_data = {}
        for table in REQUIRED_TABLES:
            if table in existing_data and not existing_data[table].empty:
                # ä¿ç•™ç°æœ‰æ•°æ®ï¼Œä½†ç¡®ä¿åˆ—ç»“æ„æ­£ç¡®
                existing_df = existing_data[table]
                template_df = new_data[table]

                # æ·»åŠ ç¼ºå¤±çš„åˆ—
                for col in template_df.columns:
                    if col not in existing_df.columns:
                        if col in ["å…¥åº“æ•°é‡", "å‡ºåº“æ€»æ•°é‡", "åº“å­˜æ•°é‡", "åœ°å€ç±»å‹", "æ¥¼å±‚"]:
                            existing_df[col] = 0
                        elif col == "çŠ¶æ€":
                            existing_df[col] = "å·²å…¥åº“"
                        elif col == "å•ä½":
                            existing_df[col] = "æ¡†"
                        else:
                            existing_df[col] = ""

                # ç§»é™¤å¤šä½™çš„åˆ—
                for col in existing_df.columns:
                    if col not in template_df.columns:
                        existing_df = existing_df.drop(columns=[col])

                merged_data[table] = existing_df
            else:
                merged_data[table] = new_data[table]

        # å†™å…¥æ–‡ä»¶
        result = safe_write_csv_files(merged_data)
        if result:
            print("âœ… CSVæ–‡ä»¶åˆ›å»º/åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âŒ CSVæ–‡ä»¶åˆ›å»ºå¤±è´¥")
        return result

    except Exception as e:
        print(f"âŒ åˆ›å»ºCSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return False


# ------------------- æ•°æ®ä¿®å¤å‡½æ•° -------------------
@timing_decorator
def repair_csv_structure(data):
    """ä¿®å¤CSVæ•°æ®ç»“æ„ - å®‰å…¨çš„ä¿®å¤æµç¨‹"""
    timing_tracker.start_operation("repair_csv_structure")
    try:
        # é¦–å…ˆè¯»å–ç°æœ‰æ•°æ®ä½œä¸ºåŸºå‡†
        existing_data = safe_read_csv_files()

        # ç”¨ç°æœ‰æ•°æ®å¡«è¡¥ç¼ºå¤±çš„è¡¨
        for table in REQUIRED_TABLES:
            if table not in data or data[table] is None or data[table].empty:
                if table in existing_data and not existing_data[table].empty:
                    data[table] = existing_data[table]
                else:
                    data[table] = get_empty_dataframe_template(table)

        # ä¿®å¤å„ä¸ªè¡¨çš„ç»“æ„
        repair_functions = {
            'inventory': repair_inventory_table,
            'manufacturer': repair_manufacturer_table,
            'feature': repair_feature_table,
            'stock_capacity': repair_stock_capacity_table,
            'stock_out_records': repair_stock_out_records_table
        }

        for table, repair_func in repair_functions.items():
            if table in data:
                data[table] = repair_func(data[table], data)

        # ä¿å­˜ä¿®å¤åçš„æ•°æ®
        result = safe_write_csv_files(data)

        timing_tracker.end_operation()
        if result:
            print("âœ… CSVæ–‡ä»¶ä¿®å¤æˆåŠŸ")
        else:
            print("âŒ CSVæ–‡ä»¶ä¿®å¤å¤±è´¥")
        return result

    except Exception as e:
        timing_tracker.end_operation()
        print(f"âŒ ä¿®å¤CSVç»“æ„å¤±è´¥: {str(e)}")
        return False


def repair_inventory_table(inventory_df, all_data):
    """ä¿®å¤åº“å­˜è¡¨ç»“æ„"""
    required_cols = get_required_columns('inventory')

    # æ·»åŠ ç¼ºå¤±çš„åˆ—
    for col in required_cols:
        if col not in inventory_df.columns:
            if col in ["å…¥åº“æ•°é‡", "å‡ºåº“æ€»æ•°é‡", "åº“å­˜æ•°é‡", "åœ°å€ç±»å‹", "æ¥¼å±‚"]:
                inventory_df[col] = 0
            elif col == "çŠ¶æ€":
                inventory_df[col] = "å·²å…¥åº“"
            elif col == "å•ä½":
                inventory_df[col] = "æ¡†"
            else:
                inventory_df[col] = ""

    # è®¡ç®—åº“å­˜æ•°é‡
    if "å…¥åº“æ•°é‡" in inventory_df.columns and "å‡ºåº“æ€»æ•°é‡" in inventory_df.columns:
        inventory_df["åº“å­˜æ•°é‡"] = inventory_df["å…¥åº“æ•°é‡"] - inventory_df["å‡ºåº“æ€»æ•°é‡"]

        # æ›´æ–°çŠ¶æ€
        inventory_df["çŠ¶æ€"] = np.where(
            inventory_df["åº“å­˜æ•°é‡"] > 0,
            "å·²å…¥åº“",
            np.where(inventory_df["åº“å­˜æ•°é‡"] == 0, "å·²å‡ºåº“", "æœªçŸ¥åº“å­˜")
        )

    return inventory_df


def repair_manufacturer_table(manufacturer_df, all_data):
    """ä¿®å¤å‚å®¶è¡¨ç»“æ„"""
    required_cols = get_required_columns('manufacturer')
    for col in required_cols:
        if col not in manufacturer_df.columns:
            manufacturer_df[col] = ""
    return manufacturer_df


def repair_feature_table(feature_df, all_data):
    """ä¿®å¤ç‰¹å¾è¡¨ç»“æ„"""
    required_cols = get_required_columns('feature')
    for col in required_cols:
        if col not in feature_df.columns:
            if col in ["å•ä»·", "é‡é‡"]:
                feature_df[col] = 0.0
            else:
                feature_df[col] = ""
    return feature_df


def repair_stock_capacity_table(stock_capacity_df, all_data):
    """ä¿®å¤åº“å­˜å®¹é‡è¡¨ç»“æ„"""
    # è·å–æ‰€æœ‰ä½¿ç”¨çš„æ¥¼å±‚
    inventory_df = all_data.get('inventory', pd.DataFrame())
    inventory_list = inventory_df.to_dict('records') if not inventory_df.empty else []

    existing_floors = set(stock_capacity_df["æ¥¼å±‚"].tolist()) if "æ¥¼å±‚" in stock_capacity_df.columns else set()

    for floor in FLOORS:
        if floor not in existing_floors:
            used_boxes = len(get_unique_boxes_by_floor(floor, inventory_list))
            new_row = pd.DataFrame([{
                "æ¥¼å±‚": floor,
                "æ¥¼å±‚å®¹é‡": FLOOR_CAPACITY,
                "æ¥¼å±‚å‰©ä½™å®¹é‡": max(0, FLOOR_CAPACITY - used_boxes)
            }])
            stock_capacity_df = pd.concat([stock_capacity_df, new_row], ignore_index=True)

    return stock_capacity_df


def repair_stock_out_records_table(stock_out_records_df, all_data):
    """ä¿®å¤å‡ºåº“è®°å½•è¡¨ç»“æ„"""
    required_cols = get_required_columns('stock_out_records')
    for col in required_cols:
        if col not in stock_out_records_df.columns:
            if col == "å‡ºåº“æ•°é‡":
                stock_out_records_df[col] = 0
            else:
                stock_out_records_df[col] = ""
    return stock_out_records_df


# ------------------- å…¼å®¹æ€§å‡½æ•° -------------------
def init_or_fix_excel_file():
    """å…¼å®¹æ€§å‡½æ•°ï¼Œä¿æŒåŸæœ‰æ¥å£"""
    return init_or_fix_csv_files()


# ------------------- ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•° -------------------
@timing_decorator
def demo_safe_data_addition():
    """æ¼”ç¤ºå®‰å…¨çš„æ•°æ®æ·»åŠ æµç¨‹"""
    print("\n" + "=" * 50)
    print("æ¼”ç¤ºå®‰å…¨æ•°æ®æ·»åŠ æµç¨‹")
    print("=" * 50)

    # 1. åˆå§‹åŒ–CSVæ–‡ä»¶
    print("1. åˆå§‹åŒ–CSVæ–‡ä»¶...")
    init_or_fix_csv_files()

    # 2. è¯»å–ç°æœ‰æ•°æ®
    from read_utils import read_csv_data
    print("2. è¯»å–ç°æœ‰æ•°æ®...")
    data = read_csv_data()

    # 3. å‡†å¤‡æ–°æ•°æ®
    print("3. å‡†å¤‡æ–°æ•°æ®...")
    new_inventory_data = {
        "ID": [generate_auto_id_df(data['inventory'])],
        "å•†å“ç¼–å·": ["TEST001"],
        "å…¥åº“æ—¶é—´": [datetime.now().strftime("%Y-%m-%d %H:%M:%S")],
        "å…¥åº“æ•°é‡": [100],
        "å‡ºåº“æ€»æ•°é‡": [0],
        "çŠ¶æ€": ["å·²å…¥åº“"],
        "åº“å­˜æ•°é‡": [100],
        "åœ°å€ç±»å‹": [1],
        "æ¥¼å±‚": [1],
        "æ¶å·": ["A"],
        "æ¡†å·": ["01"],
        "åŒ…å·": [""],
        "å•ä½": ["æ¡†"]
    }

    new_inventory_df = pd.DataFrame(new_inventory_data)

    # 4. å®‰å…¨æ·»åŠ æ•°æ®
    from write_utils import add_data_to_csv
    print("4. å®‰å…¨æ·»åŠ æ•°æ®...")
    result = add_data_to_csv({
        'inventory': new_inventory_df
    })

    if result:
        print("âœ… æ¼”ç¤ºå®Œæˆï¼šæ•°æ®å®‰å…¨æ·»åŠ æˆåŠŸ")
    else:
        print("âŒ æ¼”ç¤ºå¤±è´¥ï¼šæ•°æ®æ·»åŠ å¤±è´¥")

    return result


@timing_decorator
def performance_test():
    """æ€§èƒ½æµ‹è¯•å‡½æ•°ï¼Œæµ‹è¯•æ‰€æœ‰è¯»å†™æ“ä½œçš„æ‰§è¡Œæ—¶é—´"""
    print("ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•...")

    # é‡ç½®æ—¶é—´ç»Ÿè®¡
    global timing_tracker
    timing_tracker = TimingTracker()

    # æµ‹è¯•è¯»å–æ“ä½œ
    print("\nğŸ“Š è¯»å–æ“ä½œæµ‹è¯•:")
    from read_utils import read_csv_data, read_csv_data_cached
    data1 = read_csv_data()
    data2 = read_csv_data_cached()

    # æµ‹è¯•å†™å…¥æ“ä½œï¼ˆåˆ›å»ºæµ‹è¯•æ•°æ®ï¼‰
    print("\nğŸ’¾ å†™å…¥æ“ä½œæµ‹è¯•:")
    from write_utils import write_csv_data, write_csv_data_optimized
    test_data = data1.copy()
    write_csv_data(test_data)
    write_csv_data_optimized(test_data)

    # æµ‹è¯•å®‰å…¨æ•°æ®æ·»åŠ 
    print("\nâ• å®‰å…¨æ•°æ®æ·»åŠ æµ‹è¯•:")
    demo_safe_data_addition()

    # æ‰“å°è¯¦ç»†ç»Ÿè®¡
    timing_tracker.print_summary()

    print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")


# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œæ¼”ç¤ºå’Œæµ‹è¯•
if __name__ == "__main__":
    # æ‰§è¡Œæ¼”ç¤º
    demo_safe_data_addition()

    # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
    performance_test()