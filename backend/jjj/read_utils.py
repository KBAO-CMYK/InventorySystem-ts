# read_utils.py
import pandas as pd
import numpy as np
from functools import lru_cache
import shutil
import os
import glob
from datetime import datetime
from config import *

# ------------------- ç‹¬ç«‹æ—¶é—´æµ‹é‡ç³»ç»Ÿ -------------------
class TimingTracker:
    """ç‹¬ç«‹çš„æ—¶é—´è·Ÿè¸ªå™¨ï¼Œé¿å…ç´¯ç§¯æ—¶é•¿é—®é¢˜"""

    def __init__(self):
        self.timings = {}
        self.current_operation = None
        self.operation_start = None

    def start_operation(self, operation_name):
        """å¼€å§‹ä¸€ä¸ªæ–°çš„æ“ä½œè®¡æ—¶"""
        if self.current_operation and self.operation_start:
            # å¦‚æœæœ‰æœªç»“æŸçš„æ“ä½œï¼Œå…ˆè®°å½•å®ƒ
            elapsed = (datetime.now() - self.operation_start).total_seconds() * 1000
            if self.current_operation not in self.timings:
                self.timings[self.current_operation] = []
            self.timings[self.current_operation].append(elapsed)

        self.current_operation = operation_name
        self.operation_start = datetime.now()

    def end_operation(self):
        """ç»“æŸå½“å‰æ“ä½œå¹¶è®°å½•æ—¶é—´"""
        if self.current_operation and self.operation_start:
            elapsed = (datetime.now() - self.operation_start).total_seconds() * 1000
            if self.current_operation not in self.timings:
                self.timings[self.current_operation] = []
            self.timings[self.current_operation].append(elapsed)

            print(f"â±ï¸  {self.current_operation}: {elapsed:.2f}ms")

        self.current_operation = None
        self.operation_start = None

    def get_summary(self):
        """è·å–æ—¶é—´ç»Ÿè®¡æ‘˜è¦"""
        summary = {}
        for operation, times in self.timings.items():
            if times:
                summary[operation] = {
                    'count': len(times),
                    'total_ms': sum(times),
                    'avg_ms': sum(times) / len(times),
                    'min_ms': min(times),
                    'max_ms': max(times)
                }
        return summary

    def print_summary(self):
        """æ‰“å°è¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡"""
        print("\n" + "=" * 50)
        print("ğŸ“Š æ“ä½œæ—¶é—´ç»Ÿè®¡æ‘˜è¦")
        print("=" * 50)

        summary = self.get_summary()
        for operation, stats in summary.items():
            print(f"{operation}:")
            print(f"  è°ƒç”¨æ¬¡æ•°: {stats['count']}")
            print(f"  æ€»è€—æ—¶: {stats['total_ms']:.2f}ms")
            print(f"  å¹³å‡è€—æ—¶: {stats['avg_ms']:.2f}ms")
            print(f"  æœ€å°è€—æ—¶: {stats['min_ms']:.2f}ms")
            print(f"  æœ€å¤§è€—æ—¶: {stats['max_ms']:.2f}ms")
            print()


# å…¨å±€æ—¶é—´è·Ÿè¸ªå™¨å®ä¾‹
timing_tracker = TimingTracker()


def timing_decorator(func):
    """ç‹¬ç«‹çš„æ—¶é—´æµ‹é‡è£…é¥°å™¨"""

    def wrapper(*args, **kwargs):
        timing_tracker.start_operation(func.__name__)
        result = func(*args, **kwargs)
        timing_tracker.end_operation()
        return result

    return wrapper


# ------------------- CSVæ–‡ä»¶è·¯å¾„å®šä¹‰ -------------------
CSV_DIR = 'csv'
CSV_FILES = {
    'inventory': os.path.join(CSV_DIR, 'inventory.csv'),
    'manufacturer': os.path.join(CSV_DIR, 'manufacturer.csv'),
    'feature': os.path.join(CSV_DIR, 'feature.csv'),
    'stock_capacity': os.path.join(CSV_DIR, 'stock_capacity.csv'),
    'stock_out_records': os.path.join(CSV_DIR, 'stock_out_records.csv')
}


@timing_decorator
def ensure_csv_directory():
    """ç¡®ä¿CSVç›®å½•å­˜åœ¨"""
    if not os.path.exists(CSV_DIR):
        os.makedirs(CSV_DIR)
        print(f"åˆ›å»ºCSVç›®å½•: {CSV_DIR}")


@lru_cache(maxsize=1)
def get_cached_csv_data():
    """ç¼“å­˜CSVæ•°æ®ï¼Œ1åˆ†é’Ÿè‡ªåŠ¨å¤±æ•ˆ"""
    timing_tracker.start_operation("get_cached_csv_data")
    data = safe_read_csv_files()
    for table in REQUIRED_TABLES:
        if table not in data:
            data[table] = pd.DataFrame()
    timing_tracker.end_operation()
    return data


def invalidate_cache():
    """å¤±æ•ˆç¼“å­˜ï¼ˆæ•°æ®æ›´æ–°æ—¶è°ƒç”¨ï¼‰"""
    get_cached_csv_data.cache_clear()


@timing_decorator
def safe_read_csv_files():
    """å®‰å…¨åœ°è¯»å–æ‰€æœ‰CSVæ–‡ä»¶ - å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨è¿”å›ç©ºDataFrame"""
    data = {}
    try:
        for table, filepath in CSV_FILES.items():
            if os.path.exists(filepath):
                try:
                    # å°è¯•è¯»å–CSVæ–‡ä»¶
                    df = pd.read_csv(filepath)
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæ–‡ä»¶
                    if df.empty or (len(df.columns) == 1 and df.columns[0] == 'Unnamed: 0'):
                        data[table] = pd.DataFrame()
                    else:
                        data[table] = df.fillna("")
                    print(f"âœ… æˆåŠŸè¯»å– {table} æ•°æ®ï¼Œè¡Œæ•°: {len(data[table])}")
                except Exception as e:
                    print(f"âš ï¸ è¯»å– {table} æ–‡ä»¶å¤±è´¥: {str(e)}ï¼Œå°è¯•ä»å¤‡ä»½æ¢å¤")
                    # å°è¯•ä»å¤‡ä»½æ¢å¤
                    backup_file = f"{filepath}.backup"
                    if os.path.exists(backup_file):
                        try:
                            shutil.copy2(backup_file, filepath)
                            df = pd.read_csv(filepath)
                            data[table] = df.fillna("")
                            print(f"ğŸ”„ ä»å¤‡ä»½æ¢å¤ {table} æ•°æ®æˆåŠŸ")
                        except Exception as backup_error:
                            print(f"âŒ å¤‡ä»½æ¢å¤ä¹Ÿå¤±è´¥: {str(backup_error)}ï¼Œä½¿ç”¨ç©ºDataFrame")
                            data[table] = pd.DataFrame()
                    else:
                        print(f"ğŸ“ æ— å¤‡ä»½å¯ç”¨ï¼Œä½¿ç”¨ç©ºDataFrame")
                        data[table] = pd.DataFrame()
            else:
                print(f"ğŸ“ {table} æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºDataFrame")
                data[table] = pd.DataFrame()
        return data
    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return {table: pd.DataFrame() for table in CSV_FILES.keys()}


@timing_decorator
def read_csv_data():
    """è¯»å–CSVæ•°æ® - ä¼˜å…ˆä»ç¼“å­˜è¯»å–"""
    return get_cached_csv_data()


# ------------------- ç¼“å­˜ä¼˜åŒ– -------------------
_data_cache = {}
_cache_timestamp = None


@timing_decorator
def read_csv_data_cached():
    """å¸¦ç¼“å­˜çš„æ•°æ®è¯»å–å‡½æ•°"""
    global _data_cache, _cache_timestamp

    current_time = datetime.now()
    if (_cache_timestamp and
            (current_time - _cache_timestamp).total_seconds() < CACHE_TIMEOUT and
            _data_cache):
        return _data_cache.copy()

    data = read_csv_data()
    _data_cache = data.copy()
    _cache_timestamp = current_time

    return data


# ------------------- å…¼å®¹æ€§å‡½æ•° -------------------
def read_excel_data():
    """å…¼å®¹æ€§å‡½æ•°ï¼Œä¿æŒåŸæœ‰æ¥å£"""
    return read_csv_data()


def safe_read_excel_file():
    """å…¼å®¹æ€§å‡½æ•°ï¼Œä¿æŒåŸæœ‰æ¥å£"""
    return safe_read_csv_files()